## 경량화
딥러닝 모델은 다양한 분야에서 좋은 성능을 보이고 있다. 그러나 대부분 효과적인 모델들은 크고 복잡한 구조를 가지고 있음. 그래서 훈련 및 추론에 많은 계산 리소스가 필요하다는 한계가 존재한다.

이러한 모델들은 제한된 디바이스 환경에서 사용이 어려움. 이런 제약사항들로 인해 경량화의 필요성이 대두
### AI Edge Computing
+ 낮은 대역폭 요구: 엣지 디바이스에서 모델을 실행하면 클라우드로의 데이터 트래픽이 감소. 특히, 대규모 데이터를 전송해야 하는 경우 더 낮은 대역폭이 필요하며 네트워크 비용을 절감하고 네트워크 혼잡을 피할 수 있다.
+ 실시간 응답: 엣지에서 AI 모델을 실행함으로써 실시간 응답이 가능해진다. 이는 응용 분야에서 중요한 요소로, 자율 주행 차량, 산업 자동화, 의료 등 다양한 분야에서 실시간 응용이 필요한 경우에 유용
+ 향상된 개인 정보 보호: 사용자 데이터가 로컬에서 처리되기 때문에 민감한 정보의 전송이 최소화된다. 이는 개인정보보호 및 규정 준수에 도움이 되며, 사용자들의 신뢰를 유지할 수 있다
+ 오프라인 기능: 엣지 디바이스에서 AI 모델을 실행하면 네트워크 연결이 불안정한 상황에서도 작동할 수 있다. 이는 필드나 원격 지역에서의 응용이나 이동성이 필요한 경우에 유용하다
### 실제 사례
+ Nvidia Jetson - Nvidia 임베디드 보드 시리즈
+ cctv 내 추가 모듈 설치해 사용
### 방법
+ 알고리즘 경량화
	+ 가지치기(pruning)
	+ 양자화(quantization)
+ 효율적 딥러닝 네트워크 구조 설계
	+ Squeezenet
	+ MobileNet

#### ResNet
+ Residual Block을 통해 레이어를 깊게 쌓으면서도 파라미터를 줄이는 전략 사용
+ 1x1 convolution
	+ 차원축소: 입력 텐서의 채널 차원에 대해 연산을 수행하며, 출력 채널을 적절히 설정하면 입력의 공간 차원은 그대로 유지되면서 채널 수를 감소시킬 수 있다. 이는 모델의 복잡성을 줄이고 계산 비용을 절감하면서 효과적인 차원 축소를 가능하게 한다.
	+ 비선형성 도입: 많은 수의 1x1 conv block을 사용하면 그에 비례해 비선형성인 활성화 함수를 사용한다. 이를 통해 더 복잡하고 풍부한 패턴을 인식할 수 있다.
	+ 정보 융합: 채널 간의 상호 작용을 가능하게 하여, 각 위치에서의 특징이 서로 다른 채널 간에 조합되어 모델이 더 많은 정보를 학습할 수 있도록 도와준다. 
	+ 연산 비용 감소: 입력과 출력 간의 연산이 간단하며, 계산 비용이 낮다. 따라서 모델이 더 효율적으로 학습되고 추론될 수 있다.
#### MobileNet
주로 모바일 기기 및 임베디드 시스템에서 사용되는 경량화된 딥러닝 모델. 
+ Depthwise Separable Convolution: 공간적인 특징을 학습하는 depthwise convolution이 수행되고, 그 다음에 채널 간의 관계를 학습하는 pointwise convolution을 수행. 파라미터의 수를 줄이면서도 효과적인 특징 추출이 가능
+ Width Multiplier와 Resolution Multiplier: width multiplier는 모델 채널 수를 줄이는 역할을 하며, resolution multiplier는 입력 이미지의 해상도를 줄이는 역할을 수행. 
+ Efficient Feature Extraction: 작은 커널과 효과적인 convolution 구조를 사용해 경량 모델임에도 높은 성능
+ 모바일 및 임베디드 환경 최적화: 작은 모델 크기와 높은 추론 속도를 가지고 있어 모바일 기기에서의 실시간 응용에 적합

![500](Pasted%20image%2020240616200018.png)